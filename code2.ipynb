{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from torchtext.datasets import UDPOS\n",
    "import spacy_udpipe\n",
    "from torch.utils.data import IterableDataset\n",
    "import torchdata\n",
    "from torchdata.datapipes.iter import IterableWrapper\n",
    "from torchtext.vocab import GloVe\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag.util import untag\n",
    "from conllu import parse\n",
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "from functools import partial\n",
    "from torch.nn import init\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train_data = open('en_ewt-ud-train.conllu', 'r', encoding='utf-8').read().strip().split('\\n\\n')\n",
    "test_data = open('en_ewt-ud-test.conllu', 'r', encoding='utf-8').read().strip().split('\\n\\n')\n",
    "dev_data = open('en_ewt-ud-dev.conllu', 'r', encoding='utf-8').read().strip().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_core_web_sm = spacy.load('en_core_web_sm')\n",
    "\n",
    "TEXT = torchtext.data.Field(tokenize=partial(en_core_web_sm.tokenizer, keep_spacy_tokens=True))\n",
    "UD_TAGS = torchtext.data.Field(unk_token=None)\n",
    "\n",
    "# Load the CoNLL-U data\n",
    "train_data, valid_data, test_data = torchtext.datasets.UDPOS.splits(fields=(('text', TEXT), ('udtags', UD_TAGS)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building vocabulary\n",
    "# using GloVe prebuilt embeddings to initialize (they perform better than ones we initialize)\n",
    "freq = 5\n",
    "TEXT.build_vocab(train_data,\n",
    "                 min_freq=freq,\n",
    "                 vectors=GloVe(name='6B', dim=100),\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "UD_TAGS.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size = BATCH_SIZE, device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POS_TAGGER(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = 2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        # if bidirectional:\n",
    "        #     self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        # else:\n",
    "        #     self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, text):        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(outputs)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'embedding' not in name:\n",
    "                nn.init.normal_(param.data, mean=0, std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = POS_TAGGER(len(TEXT.vocab), 100, 128, len(UD_TAGS.vocab), TEXT.vocab.stoi[TEXT.pad_token])\n",
    "model.init_weights()\n",
    "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(100)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "padding_idx = UD_TAGS.vocab['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = padding_idx)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_(pred, targ, tag_pad_idx):\n",
    "    # Step 1: Flatten the inputs\n",
    "    pred = pred.view(-1, pred.shape[-1])\n",
    "    targ = targ.view(-1)  \n",
    "    \n",
    "    # Step 2: Ignore the pad elements\n",
    "    non_pad_elements = targ != tag_pad_idx\n",
    "    \n",
    "    # Step 3: Get the index of the max probability\n",
    "    max_preds = pred.argmax(dim=1) \n",
    "    \n",
    "    # Step 4: Count the number of correct predictions\n",
    "    correct = max_preds[non_pad_elements].eq(targ[non_pad_elements])\n",
    "    num_correct = correct.sum().item()\n",
    "    \n",
    "    # Step 5: Calculate the accuracy\n",
    "    num_total = non_pad_elements.sum().item()\n",
    "    acc = num_correct / num_total\n",
    "    \n",
    "    return torch.tensor(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, padding_idx):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator: \n",
    "        text = batch.text\n",
    "        tags = batch.udtags\n",
    "        \n",
    "        # Step 6.1: zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Step 6.2: insert the batch of text into the model to get predictions\n",
    "        predictions = model(text)\n",
    "        # Step 6.3: reshape the predictions\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        # Step 6.4: calculate loss and accuracy between the predicted tags and actual tags\n",
    "        loss = criterion(predictions, tags)\n",
    "        acc = accuracy_(predictions, tags, padding_idx)\n",
    "        # Step 6.5: call backward to calculate the gradients of the parameters w.r.t. the loss        \n",
    "        loss.backward()\n",
    "        # Step 6.6: optimizer step to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_(model, iterator, criterion, padding_idx):\n",
    "    # model (nn.Module): The model to evaluate.\n",
    "    # iterator (torchtext.data.Iterator): The data iterator to evaluate on.\n",
    "    # criterion (nn.Module): The loss function to use for evaluation.\n",
    "    # padding_idx(int): The padding index for the tags.\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, tags = batch.text, batch.udtags\n",
    "            predictions = model(text)\n",
    "            batch_size, seq_len, n_tags = predictions.shape\n",
    "            predictions = predictions.view(-1, n_tags)\n",
    "            tags = tags.view(-1)\n",
    "            loss = criterion(predictions, tags)\n",
    "            acc = accuracy_(predictions, tags, padding_idx)\n",
    "            epoch_loss += loss.item() * batch.batch_size\n",
    "            epoch_acc += acc.item() * batch.batch_size\n",
    "            predicted_labels.extend(torch.argmax(predictions, dim=-1).tolist())\n",
    "            true_labels.extend(tags.tolist())\n",
    "\n",
    "        target_names = [UD_TAGS.vocab.itos[i] for i in range(len(UD_TAGS.vocab))]\n",
    "        report = classification_report(true_labels, predicted_labels, target_names=target_names, output_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.381 | Train Acc: 87.53%\n",
      "\tVal. Loss: 67.372 | Val. Acc: 10408.52%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.370 | Train Acc: 87.87%\n",
      "\tVal. Loss: 67.012 | Val. Acc: 10512.13%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.363 | Train Acc: 88.05%\n",
      "\tVal. Loss: 67.032 | Val. Acc: 10382.02%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.355 | Train Acc: 88.33%\n",
      "\tVal. Loss: 66.682 | Val. Acc: 10443.39%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.349 | Train Acc: 88.49%\n",
      "\tVal. Loss: 67.038 | Val. Acc: 10423.22%\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.345 | Train Acc: 88.54%\n",
      "\tVal. Loss: 66.265 | Val. Acc: 10517.83%\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.337 | Train Acc: 88.77%\n",
      "\tVal. Loss: 65.761 | Val. Acc: 10536.38%\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.331 | Train Acc: 89.00%\n",
      "\tVal. Loss: 65.682 | Val. Acc: 10540.01%\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.327 | Train Acc: 89.10%\n",
      "\tVal. Loss: 65.414 | Val. Acc: 10459.50%\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.322 | Train Acc: 89.22%\n",
      "\tVal. Loss: 65.546 | Val. Acc: 10545.77%\n"
     ]
    }
   ],
   "source": [
    "# N_EPOCHS = 10\n",
    "\n",
    "# best_valid_loss = float('inf')\n",
    "\n",
    "# for epoch in range(N_EPOCHS):\n",
    "#     train_loss, train_acc = train(model, train_iterator, optimizer, criterion, padding_idx)\n",
    "#     valid_loss, valid_acc, REPORT_ = eval_(model, valid_iterator, criterion, padding_idx)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'trained_model.pt')\n",
    "\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1:02}')\n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4938}, 'NOUN': {'precision': 0.5814134495641345, 'recall': 0.8899213724088635, 'f1-score': 0.7033236041803974, 'support': 4197}, 'PUNCT': {'precision': 0.9931707317073171, 'recall': 0.990593577684074, 'f1-score': 0.991880480675544, 'support': 3083}, 'VERB': {'precision': 0.7133333333333334, 'recall': 0.8129522431259045, 'f1-score': 0.7598917822117011, 'support': 2764}, 'PRON': {'precision': 0.6624843161856964, 'recall': 0.9522091974752029, 'f1-score': 0.781354051054384, 'support': 2218}, 'ADP': {'precision': 0.8756428237494156, 'recall': 0.925852694018784, 'f1-score': 0.9000480538202789, 'support': 2023}, 'DET': {'precision': 0.956386292834891, 'recall': 0.9720316622691293, 'f1-score': 0.9641455116461659, 'support': 1895}, 'PROPN': {'precision': 0.38359543632439097, 'recall': 0.6624068157614483, 'f1-score': 0.48584260886545594, 'support': 1878}, 'ADJ': {'precision': 0.765695067264574, 'recall': 0.7635550586920067, 'f1-score': 0.7646235656311222, 'support': 1789}, 'AUX': {'precision': 0.89875, 'recall': 0.9529489728296885, 'f1-score': 0.9250562881955613, 'support': 1509}, 'ADV': {'precision': 0.882940108892922, 'recall': 0.768562401263823, 'f1-score': 0.8217905405405405, 'support': 1266}, 'CCONJ': {'precision': 0.9909443725743855, 'recall': 0.982051282051282, 'f1-score': 0.9864777849323889, 'support': 780}, 'PART': {'precision': 0.8772727272727273, 'recall': 0.919047619047619, 'f1-score': 0.8976744186046511, 'support': 630}, 'NUM': {'precision': 0.6201923076923077, 'recall': 0.6825396825396826, 'f1-score': 0.6498740554156172, 'support': 378}, 'SCONJ': {'precision': 0.7463556851311953, 'recall': 0.6368159203980099, 'f1-score': 0.687248322147651, 'support': 402}, 'X': {'precision': 0.390625, 'recall': 0.16233766233766234, 'f1-score': 0.2293577981651376, 'support': 154}, 'INTJ': {'precision': 0.37662337662337664, 'recall': 0.5043478260869565, 'f1-score': 0.4312267657992565, 'support': 115}, 'SYM': {'precision': 0.7333333333333333, 'recall': 0.4925373134328358, 'f1-score': 0.5892857142857143, 'support': 67}, 'accuracy': 0.7265505550754504, 'macro avg': {'precision': 0.6915976868046667, 'recall': 0.7261506278568317, 'f1-score': 0.6982834081206426, 'support': 30086}, 'weighted avg': {'precision': 0.6349758235874491, 'recall': 0.7265505550754504, 'f1-score': 0.6710424335312928, 'support': 30086}}\n"
     ]
    }
   ],
   "source": [
    "# print(REPORT_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
    "    model.eval()\n",
    "    tokens = sentence.split()\n",
    "    token_emb = [text_field.vocab.stoi[t] for t in tokens]\n",
    "    token_tensor = (torch.LongTensor(token_emb)).unsqueeze(-1).to(device)         \n",
    "    predictions = (model(token_tensor)).argmax(-1)    \n",
    "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in predictions]\n",
    "    \n",
    "    return tokens, predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sent = input(\"input sentence: \\n\")\n",
    "input_sent = input_sent.lower()\n",
    "text = input_sent\n",
    "# Replace multiple spaces with a single space\n",
    "text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "# replace numbers with <NUM>\n",
    "text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" <NUM> \", text)\n",
    "text = re.sub(r'\\b\\d+\\w*\\b', '<NUM>', text)\n",
    "text = re.sub(r'\\w*\\d\\w*', '<NUM>', text)\n",
    "\n",
    "# contractions\n",
    "text = re.sub(r\"can't\", \"can not\", text)\n",
    "text = re.sub(r\"won't\", \"will not\", text)\n",
    "\n",
    "# hypens and underscore characters at beginning and end of words\n",
    "text = re.sub(r'(\\b|\\-|_)(\\w+)\\-?(\\b|\\-|_)', r'\\2 ', text)\n",
    "text = re.sub(r'(\\b|\\-|_)(\\w+)\\-?(\\b|\\-|_)', r'\\2 ', text)\n",
    "\n",
    "# Ensure that there's a space between punctuation and words\n",
    "text = re.sub(r'(\\w)([.,!?])', r'\\1 \\2', text)\n",
    "text = re.sub(r'([.,!?])(\\w)', r'\\1 \\2', text)\n",
    "\n",
    "# Replace URLs with <URL>\n",
    "text = re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '<URL>', text)\n",
    "\n",
    "# Replace hashtags with <HASHTAG>\n",
    "text = re.sub(r'#\\w+', '<HASHTAG>', text)\n",
    "\n",
    "# Replace mentions with <MENTION>\n",
    "text = re.sub(r'@\\w+', '<MENTION>', text)\n",
    "\n",
    "# Replace with <PERCENT>\n",
    "text = re.sub(r'(\\d+(\\.\\d+)?%)', \"<PERCENT>\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too many! it/they felt the force of the gravity of an earth even though the stuff was kinda heavy...\n"
     ]
    }
   ],
   "source": [
    "print(input_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "ADV\t\ttoo\n",
      "ADJ\t\tmany!\n",
      "NOUN\t\tit/they\n",
      "VERB\t\tfelt\n",
      "DET\t\tthe\n",
      "NOUN\t\tforce\n",
      "ADP\t\tof\n",
      "DET\t\tthe\n",
      "NOUN\t\tgravity\n",
      "ADP\t\tof\n",
      "DET\t\tan\n",
      "NOUN\t\tearth\n",
      "ADV\t\teven\n",
      "SCONJ\t\tthough\n",
      "DET\t\tthe\n",
      "NOUN\t\tstuff\n",
      "AUX\t\twas\n",
      "ADJ\t\tkinda\n",
      "VERB\t\theavy...\n"
     ]
    }
   ],
   "source": [
    "tokens, pred_tags = tag_sentence(model, device, input_sent, TEXT, UD_TAGS)\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "for token, pred_tag in zip(tokens, pred_tags):\n",
    "    print(f\"{pred_tag}\\t\\t{token}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
